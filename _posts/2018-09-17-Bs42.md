---
layout: article
title: "[Dev]BeautifulSoup"
key: 20180917
tags:
  - Dev
  - ML
toc: true
mathjax: true
mathjax_autoNumber: true
published : true
---

# [+] Python BeautifulSoup

<!--more-->

## [+] BeautifulSoup

### id attribute

BeautifulSoup 모듈을 이용해 웹 스크래핑을 하는 여러가지 방법 중 id 속성을 이용해 요소를 찾는 방법이다.

```python
#-*-coding:utf-8-*-
import bs4,sys
reload(sys)
sys.setdefaultencoding('utf-8')
html='''
<html><body>
    <h1 id="title">스크래핑!</h1>
    <p id="body">분석!</p>
    <p>허허헛!</p>
</body></html>
'''
data=bs4.BeautifulSoup(html,'html.parser')

title=data.find(id='title')
body=data.find(id='body')
print 'title = {}, body = {}'.format(title.string,body.string)
```

위와 같이 'id' 속성을 지정해서 사용이 가능하다.  find 메소드는 이 외에도 참 유용하다.

### find_all

find_all 메소드의 경우 여러 태그를 한번에 추출할 수 있다.

```python
import bs4,sys
reload(sys)
sys.setdefaultencoding('utf-8')
#from bs4 import BeautifulSoup
html="""
<html><body>
    <ul>
        <li><a href="https://www.naver.com">Naver</a></li>
        <li><a href="https://google.co.kr">Google</a></li>
    </body></html>
    """

soup=bs4.BeautifulSoup(html,'html.parser')

link=soup.find_all("a")
for a in link:
    href=a.attrs['href']
    text=a.string
    print '{} -> {}'.format(text,href)
```

```
Naver -> https://www.naver.com
Google -> https://google.co.kr
```

잘된다. 븨유티풀

### urlopen() & bs

이번엔 urlopen() 을 이용하여 기상청에서 날씨를 가져오는 프로그램을 짜본다..

```python
#-*-coding:utf-8-*-
import bs4,sys,urllib as url
reload(sys)
sys.setdefaultencoding('utf-8')
fore='http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp'
resp=url.urlopen(fore)

soup=bs4.BeautifulSoup(resp,'html.parser')

title=soup.find('title').string
wf=soup.find('wf').string
print title
print wf
```

```
기상청 육상 중기예보
기압골의 영향으로 21일은 전국에 비가 오겠고, 그 밖의 날은 고기압의 영향으로 대체로 맑은 날이 많겠습니다.<br />기온은 평년(최저기온: 10~19℃, 최고기온: 22~27℃)과 비슷하거나 조금 낮겠습니다.<br />강수량은 평년(2~8mm)보다 많겠습니다.
```

urlopen을 이용해 해당 url 요청에 대한 응답을 'resp' 에 담는다.
beautifulsoup을 이용하여 'soup'을 생성하고 find 메소드를 이용해 각 요소들을 추출해 결과를 출력한다.

### use CSS

CSS 선택자를 지정하여 요소를 추출할 수 있다.!

```python
#-*-coding:utf-8-*-
import bs4,sys
reload(sys)
sys.setdefaultencoding('utf-8')

html='''
<html><body>
<div id="meigen">
    <h1>위키북스</h1>
    <ul class="items">
        <li>파이썬을 이용한 머신러닝</li>
        <li>실습!</li>
        <li>Shh0ya</li>
    </ul>
</div>
</body></html>
'''

soup=bs4.BeautifulSoup(html,'html.parser')

h1 = soup.select_one("div#meigen > h1").string
print 'h1 : {}'.format(h1)
li_list=soup.select("div#meigen > ul.items > li")
for i in li_list:
    print 'li : {}'.format(i.string)
```

```
h1 : 위키북스
li : 파이썬을 이용한 머신러닝
li : 실습!
li : Shh0ya
```

우오옹오오오오 마찬가지로 soup 생성까지는 위와 동일하다. 그러나 이후 사용되는 select_one과 select는 이름을 보면 알 수 있듯이 select_one은 하나의 요소만을 추출, select의 경우 여러개의 요소를 한번에 추출할 수 있다.

### Example

금융에서 환율 정보추출하기! 이 책 뭔가 참 좋다. 실습도 깔끔하고 뭔가 유익하다

```python
#-*-coding:utf-8-*-
import bs4,sys
import urllib as ur
reload(sys)
sys.setdefaultencoding('utf-8')

url = 'https://finance.naver.com/marketindex/'
resp = ur.urlopen(url)

soup=bs4.BeautifulSoup(resp,'html.parser')

price = soup.select_one('div.head_info > span.value').string
print "USD/KRW : {}".format(price)
```

```
USD/KRW : 1,124.00
```

CSS 라니...

다음은 위키에 있는 윤동주 시인님의 작품을 출력해본다.

```python
#-*-coding:utf-8-*-
import bs4,sys
import urllib as ur
reload(sys)
sys.setdefaultencoding('utf-8')

url ='https://ko.wikipedia.org/wiki/하늘과_바람과_별과_시'
resp =ur.urlopen(url)
soup = bs4.BeautifulSoup(resp,'html.parser')

title = soup.select('#mw-content-text > div > ul > li > a')
list_l=len(title)

for i in title:
    if i.string == title[list_l-2].string:
        break
    print i.string
```

```
자화상
새로운 길
슬픈 족속
소년
병원
무서운 시간
눈 오는 지도
태초의 아침
또 태초의 아침
새벽이 올 때까지
십자가
눈 감고 간다
돌아와 보는 밤
간판 없는 거리
바람이 불어
또 다른 고향
길
별 헤는 밤
서시
```

본의 아니게 뒤에 다른 내용도 존재하여 코드가 몇줄 추가 되었다.
CSS 선택자는 정말 유용하게 쓰일 수 있으나 아직 불편한건 사실이다.

```python
#-*-coding:utf-8-*-
import bs4,sys
import urllib as ur
reload(sys)
sys.setdefaultencoding('utf-8')

html='''
<ul id='bible'>
    <li id='ge'>Genesis</li>
    <li id='ex'>Exodus</li>
    <li id='le'>Leviticus</li>
    <li id='nu'>Number</li>
    <li id='de'>Deuteronomy</li>
</ul>
'''

soup=bs4.BeautifulSoup(html,'html.parser')
sel = lambda a: soup.select_one(a).string
id = ['#nu','li#nu','ul > li#nu','#bible #nu','#bible > #nu','ul#bible > li#nu','li[id="nu"]','li:nth-of-type(4)']
for i in id:
    print sel(i)

```

위의 코드는 CSS 선택자로 추출하는 연습을 하는 코드이다.
'id' 리스트 순서대로 설명을 보자.

1. id 속성이 'nu' 인 것을 추출
2. li 태그 내 id 속성이 'nu' 인 것을 추출
3. ul 태그 내 li 태그의 id 속성이 'nu'인 것을 추출
4. id 속성이 'bible' 내 'nu' 인 것을 추출
5. 부모자식관계로 표현
6. id가 'bible'인 ul 태그 아래 id가 'nu'인 li 태그를 추출
7. 속성 검색을 이용해 id가 'nu'인 li 태그를 추출
8. 4번째 li태그를 추출

어우 쓰다보면 익숙해지겠지만 은근히 어려운 것 같다. 아래는 좀더 복잡한 html 문서 내에서 추출을 해본다.

```python
#-*-coding:utf-8-*-
import bs4,sys,urllib
reload(sys)
sys.setdefaultencoding('utf-8')

html ='''
<html><body>
<div id="main-goods" role="page">
    <h1>과일과 야채</h1>
    <ul id="fr-list">
        <li class="red green" data-lo="ko">사과</li>
        <li class="purple" data-lo="us">포도</li>
        <li class="yellow" data-lo="us">레몬</li>
        <li class="yellow" data-lo="ko">오렌지</li>
    </ul>
    <ul id="ve-list">
        <li class="white green" data-lo="ko">무</li>
        <li class="red green" data-lo="us">파프리카</li>
        <li class="black" data-lo="ko">가지</li>
        <li class="black" data-lo="us">아보카도</li>
        <li class="white" data-lo="cn">연근</li>
    </ul>
</div>
</body></html>'''
soup=bs4.BeautifulSoup(html,"html.parser")
#CSS 선택자를 이용한 추출
print soup.select_one('li:nth-of-type(8)').string
print soup.select_one('#ve-list > li:nth-of-type(4)').string
print soup.select("#ve-list > li[data-lo='us']")[1].string
print soup.select("#ve-list > li.black")[1].string

# 딕셔너리, find를 이용한 추출
cond = {"data-lo":"us","class":"black"}
print soup.find("li",cond).string

# find를 연속적으로 이용하여 추출
print soup.find(id="ve-list").find("li",cond).string
```

모두 '아보카도' 가 추출된다. 저자는 아보카도를 좋아했나보다.
이건 자주 쓰고 많이써봐야 익숙해질 것 같다. 그리고 자주 쓰게 될 것 같다.



# [+] Reference

1. <a href="http://wikibook.co.kr/python-machine-learning/">*"파이썬을 이용한 머신러닝"*</a>



